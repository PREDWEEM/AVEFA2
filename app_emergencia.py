# app_emergencia.py ‚Äî AVEFA (lockdown + pron√≥stico completo + MA5 sombreada + sin tabla de pron√≥stico completo)
import streamlit as st
import numpy as np
import pandas as pd
from io import BytesIO, StringIO
from urllib.request import urlopen, Request
from urllib.error import HTTPError, URLError
from pathlib import Path
import plotly.graph_objects as go

# =================== LOCKDOWN UI ===================
st.set_page_config(
    page_title="Predicci√≥n de Emergencia Agr√≠cola AVEFA",
    layout="wide",
    menu_items={"Get help": None, "Report a bug": None, "About": None}
)
st.markdown(
    """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header [data-testid="stToolbar"] {visibility: hidden;}
    .viewerBadge_container__1QSob {visibility: hidden;}
    .st-emotion-cache-9aoz2h {visibility: hidden;}
    .stAppDeployButton {display: none;}
    </style>
    """,
    unsafe_allow_html=True
)

# =================== Utilidades de error seguro ===================
from typing import Callable, Any
def safe_run(fn: Callable[[], Any], user_msg: str):
    try:
        return fn()
    except Exception:
        st.error(user_msg)
        return None

# ====================== Config pesos ======================
GITHUB_BASE_URL = "https://raw.githubusercontent.com/PREDWEEM/AVEFA2/main"
FNAME_IW   = "IW.npy"
FNAME_BIW  = "bias_IW.npy"
FNAME_LW   = "LW.npy"
FNAME_BOUT = "bias_out.npy"

# ====================== Umbrales EMERREL ======================
THR_BAJO_MEDIO = 0.020
THR_MEDIO_ALTO = 0.079

# ====================== Umbrales EMEAC ======================
EMEAC_MIN_DEN = 1.8
EMEAC_ADJ_DEN = 2.1
EMEAC_MAX_DEN = 2.5

# ====================== Colores por nivel ======================
COLOR_MAP = {"Bajo": "#2ca02c", "Medio": "#ff7f0e", "Alto": "#d62728"}
COLOR_FALLBACK = "#808080"

# ====================== Utilidades de red/archivos ======================
def _fetch_bytes(url: str, timeout: int = 20) -> bytes:
    req = Request(url, headers={"User-Agent": "Mozilla/5.0"})
    try:
        with urlopen(req, timeout=timeout) as resp:
            return resp.read()
    except (HTTPError, URLError):
        raise RuntimeError("No se pudo descargar el recurso remoto.")
    except Exception:
        raise RuntimeError("Error descargando recurso remoto.")

@st.cache_data(ttl=1800)
def load_npy_from_fixed(filename: str) -> np.ndarray:
    url = f"{GITHUB_BASE_URL}/{filename}"
    raw = _fetch_bytes(url)
    return np.load(BytesIO(raw), allow_pickle=False)

@st.cache_data(ttl=900)
def load_public_csv():
    urls = [
        "https://PREDWEEM.github.io/ANN/meteo_daily.csv",
        "https://raw.githubusercontent.com/PREDWEEM/ANN/gh-pages/meteo_daily.csv"
    ]
    for url in urls:
        try:
            df = pd.read_csv(url, parse_dates=["Fecha"])
            req = {"Fecha", "Julian_days", "TMAX", "TMIN", "Prec"}
            if not req.issubset(df.columns):
                continue
            return df.sort_values("Fecha").reset_index(drop=True)
        except Exception:
            continue
    raise RuntimeError("No se pudo cargar el CSV p√∫blico.")

def validar_columnas_meteo(df: pd.DataFrame):
    req = {"Julian_days", "TMAX", "TMIN", "Prec"}
    faltan = req - set(df.columns)
    return (len(faltan) == 0, "" if not faltan else f"Faltan columnas: {', '.join(sorted(faltan))}")

def obtener_colores(niveles: pd.Series):
    return niveles.map(COLOR_MAP).fillna(COLOR_FALLBACK).to_numpy()

def _sanitize_meteo(df: pd.DataFrame) -> pd.DataFrame:
    cols = ["Julian_days", "TMAX", "TMIN", "Prec"]
    df = df.copy()
    for c in cols:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df[cols] = df[cols].interpolate(limit_direction="both")
    df["Julian_days"] = df["Julian_days"].clip(1, 366)
    df["Prec"] = df["Prec"].clip(lower=0)
    m = df["TMAX"] < df["TMIN"]
    if m.any():
        df.loc[m, ["TMAX", "TMIN"]] = df.loc[m, ["TMIN", "TMAX"]].values
    return df

# ====================== PERSISTENCIA LOCAL (CSV) ======================
# Ruta configurable por secrets: LOCAL_HISTORY_PATH y modo de fusi√≥n FREEZE_HISTORY
LOCAL_HISTORY_PATH = st.secrets.get("LOCAL_HISTORY_PATH", "avefa_history_local.csv")
FREEZE_HISTORY = bool(st.secrets.get("FREEZE_HISTORY", False))  # valor por defecto (se puede cambiar en el sidebar)

def _normalize_like_hist(df: pd.DataFrame) -> pd.DataFrame:
    """Normaliza columnas y tipos a ['Fecha','Julian_days','TMAX','TMIN','Prec'] sin cambiar valores."""
    if df is None or df.empty:
        return pd.DataFrame(columns=["Fecha","Julian_days","TMAX","TMIN","Prec"])
    out = df.copy()
    # Renombrado flexible por si cambian may√∫sculas/min√∫sculas
    out.columns = [str(c).strip() for c in out.columns]
    lower_map = {c.lower(): c for c in out.columns}
    def pick(*cands):
        for c in cands:
            if c in lower_map:
                return lower_map[c]
        return None
    mapping = {
        pick("fecha","date"): "Fecha",
        pick("julian_days","julianday","julian","doy","dia_juliano"): "Julian_days",
        pick("tmax","t_max","tx"): "TMAX",
        pick("tmin","t_min","tn"): "TMIN",
        pick("prec","ppt","precip","lluvia","mm","prcp"): "Prec",
    }
    mapping = {k: v for k, v in mapping.items() if k is not None}
    out = out.rename(columns=mapping)
    if "Fecha" in out.columns:
        out["Fecha"] = pd.to_datetime(out["Fecha"], errors="coerce")
    if "Julian_days" not in out.columns and "Fecha" in out.columns:
        out["Julian_days"] = pd.to_datetime(out["Fecha"]).dt.dayofyear
    if "Fecha" not in out.columns and "Julian_days" in out.columns:
        year = pd.Timestamp.now().year
        out["Fecha"] = pd.to_datetime(f"{year}-01-01") + pd.to_timedelta(pd.to_numeric(out["Julian_days"], errors="coerce") - 1, unit="D")
    for c in ["TMAX","TMIN","Prec","Julian_days"]:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    req = {"Fecha","Julian_days","TMAX","TMIN","Prec"}
    if not req.issubset(out.columns):
        # Devuelve lo que haya, pero ordena y limpia Fecha si existe
        if "Fecha" in out.columns:
            out = out.dropna(subset=["Fecha"])
        return out.sort_values("Fecha").reset_index(drop=True)
    out = out.dropna(subset=["Fecha"]).sort_values("Fecha").reset_index(drop=True)
    out["Julian_days"] = pd.to_datetime(out["Fecha"]).dt.dayofyear
    return out[["Fecha","Julian_days","TMAX","TMIN","Prec"]]

def _load_local_history(path: str) -> pd.DataFrame:
    p = Path(path)
    if not p.exists():
        return pd.DataFrame(columns=["Fecha","Julian_days","TMAX","TMIN","Prec"])
    try:
        df = pd.read_csv(p)
    except Exception:
        try:
            df = pd.read_excel(p)
        except Exception:
            return pd.DataFrame(columns=["Fecha","Julian_days","TMAX","TMIN","Prec"])
    return _normalize_like_hist(df)

def _save_local_history(path: str, df_hist: pd.DataFrame) -> None:
    try:
        # Guardar siempre CSV para simplicidad
        cols = ["Fecha","Julian_days","TMAX","TMIN","Prec"]
        to_write = df_hist[cols].copy() if set(cols).issubset(df_hist.columns) else df_hist.copy()
        to_write.to_csv(path, index=False, date_format="%Y-%m-%d")
    except Exception:
        # Silencioso: la app no falla por no poder persistir
        pass

def _union_histories(df_prev: pd.DataFrame, df_new: pd.DataFrame, freeze_existing: bool = False) -> pd.DataFrame:
    """Une hist√≥rico previo con nuevos datos por Fecha.
    - freeze_existing=False: PRIORIZA nuevos valores (keep='last')
    - freeze_existing=True: CONSERVA lo previo (keep='first')
    """
    prev = _normalize_like_hist(df_prev)
    new  = _normalize_like_hist(df_new)
    if prev.empty and new.empty:
        return prev
    if prev.empty:
        base = new
    elif new.empty:
        base = prev
    else:
        if freeze_existing:
            concat = pd.concat([prev, new], ignore_index=True)
            keep_mode = "first"  # conserva prev
        else:
            concat = pd.concat([prev, new], ignore_index=True)
            keep_mode = "last"   # pisa con new
        base = (concat.dropna(subset=["Fecha"])
                     .sort_values("Fecha")
                     .drop_duplicates(subset=["Fecha"], keep=keep_mode)
                     .reset_index(drop=True))
    base["Fecha"] = pd.to_datetime(base["Fecha"], errors="coerce")
    base = base.dropna(subset=["Fecha"]).sort_values("Fecha").reset_index(drop=True)
    base["Julian_days"] = base["Fecha"].dt.dayofyear
    for c in ["TMAX","TMIN","Prec"]:
        if c in base.columns:
            base[c] = pd.to_numeric(base[c], errors="coerce")
    return base

# ====================== Modelo ======================
class PracticalANNModel:
    def __init__(self, IW, bias_IW, LW, bias_out):
        self.IW = IW
        self.bias_IW = bias_IW
        self.LW = LW
        self.bias_out = float(bias_out)
        # Orden esperado: [Julian_days, TMIN, TMAX, Prec]
        self.input_min = np.array([1, -7, 0, 0], dtype=float)
        self.input_max = np.array([300, 25.5, 41, 84], dtype=float)
        self._den = np.maximum(self.input_max - self.input_min, 1e-9)

    def tansig(self, x): return np.tanh(x)
    def normalize_input(self, X):
        Xc = np.clip(X, self.input_min, self.input_max)
        return 2 * (Xc - self.input_min) / self._den - 1
    def denormalize_output(self, y, ymin=-1, ymax=1):
        return (y - ymin) / (ymax - ymin)

    def predict(self, X_real, thr_bajo_medio=THR_BAJO_MEDIO, thr_medio_alto=THR_MEDIO_ALTO):
        Xn = self.normalize_input(X_real)
        z1 = Xn @ self.IW + self.bias_IW
        a1 = self.tansig(z1)
        z2 = (a1 @ self.LW.T).ravel() + self.bias_out
        y  = self.tansig(z2)
        y  = self.denormalize_output(y)   # [0,1]
        ac = np.cumsum(y) / 8.05
        diff = np.diff(ac, prepend=0)
        niveles = np.where(diff <= thr_bajo_medio, "Bajo",
                   np.where(diff <= thr_medio_alto, "Medio", "Alto"))
        return pd.DataFrame({"EMERREL(0-1)": diff, "Nivel_Emergencia_relativa": niveles})

# ====================== UI ======================
st.title("Predicci√≥n de Emergencia Agr√≠cola AVEFA")

st.sidebar.header("Meteo")
fuente_meteo = st.sidebar.radio("Fuente meteo", ["Autom√°tico (CSV p√∫blico)", "Subir Excel meteo"])

# <<< NUEVO: opci√≥n de congelar en el men√∫ lateral >>>
FREEZE_HISTORY = st.sidebar.checkbox(
    "Congelar hist√≥rico local (no sobrescribir)",
    value=FREEZE_HISTORY,
    help="Si est√° activado, al guardar el hist√≥rico local se conservan los valores ya guardados para cada fecha."
)

if st.sidebar.button("Limpiar cach√©"):
    st.cache_data.clear()

# --- Cargar pesos ---
def _cargar_pesos():
    IW       = load_npy_from_fixed(FNAME_IW)
    bias_IW  = load_npy_from_fixed(FNAME_BIW)
    LW       = load_npy_from_fixed(FNAME_LW)
    bias_out = load_npy_from_fixed(FNAME_BOUT).item()
    assert IW.shape[0] == 4, "Dimensiones de pesos inv√°lidas."
    assert bias_IW.shape[0] == IW.shape[1], "Dimensiones de pesos inv√°lidas."
    assert LW.shape[1] == IW.shape[1] and LW.shape[0] == 1, "Dimensiones de pesos inv√°lidas."
    return IW, bias_IW, LW, bias_out

pesos = safe_run(_cargar_pesos, "No se pudieron cargar los archivos del modelo.")
if pesos is None:
    st.stop()
IW, bias_IW, LW, bias_out = pesos
modelo = PracticalANNModel(IW, bias_IW, LW, float(bias_out))

# --- Cargar meteo ---
dfs = []
if fuente_meteo == "Autom√°tico (CSV p√∫blico)":
    def _leer_public_csv():
        df = load_public_csv()
        return _sanitize_meteo(df)
    df_auto = safe_run(_leer_public_csv, "No se pudo leer la fuente meteorol√≥gica.")
    if df_auto is not None:
        # Asegurar fecha
        if "Fecha" not in df_auto.columns or not np.issubdtype(df_auto["Fecha"].dtype, np.datetime64):
            year = pd.Timestamp.now().year
            df_auto["Fecha"] = pd.to_datetime(f"{year}-01-01") + pd.to_timedelta(df_auto["Julian_days"] - 1, unit="D")
        else:
            df_auto["Fecha"] = pd.to_datetime(df_auto["Fecha"])
        df_auto = df_auto.sort_values("Fecha").reset_index(drop=True)

        hoy = pd.Timestamp.now().normalize()
        # =========== HIST√ìRICO + PRON√ìSTICO COMPLETO (sin recorte) ===========
        hist = df_auto.loc[df_auto["Fecha"] <= hoy]
        fcst = df_auto.loc[df_auto["Fecha"] >  hoy]   # <-- sin .head(7)
        if fcst.empty:
            st.warning("No hay d√≠as de pron√≥stico posteriores a hoy; se usan solo datos hist√≥ricos.")
        else:
            st.success(f"Pron√≥stico completo detectado: {len(fcst)} d√≠a(s) futuros incluidos.")
        df_auto_sel = pd.concat([hist, fcst], ignore_index=True).drop_duplicates(subset=["Fecha"])

        # ====== PERSISTENCIA: unificar con hist√≥rico local y guardar ======
        try:
            df_prev_local = _load_local_history(LOCAL_HISTORY_PATH)
            df_union = _union_histories(df_prev_local, df_auto_sel, freeze_existing=FREEZE_HISTORY)
            _save_local_history(LOCAL_HISTORY_PATH, df_union)
            df_auto_sel = df_union  # usar consolidado persistente
        except Exception:
            # ante cualquier problema de IO, seguimos con df_auto_sel sin cortar la app
            pass

        dfs.append(("Meteo (hist√≥rico + pron√≥stico completo)", df_auto_sel))
else:
    ups = st.file_uploader("Sub√≠ uno o m√°s .xlsx con columnas: Julian_days, TMAX, TMIN, Prec",
                           type=["xlsx"], accept_multiple_files=True)
    if ups:
        for f in ups:
            def _leer_xlsx():
                return pd.read_excel(f)
            df_up = safe_run(_leer_xlsx, "No se pudo leer el archivo subido.")
            if df_up is None:
                continue
            ok, msg = validar_columnas_meteo(df_up)
            if not ok:
                st.warning(f"{f.name}: {msg}")
                continue
            if "Fecha" not in df_up.columns:
                year = pd.Timestamp.now().year
                df_up["Fecha"] = pd.to_datetime(f"{year}-01-01") + pd.to_timedelta(df_up["Julian_days"] - 1, unit="D")
            df_up = _sanitize_meteo(df_up)
            dfs.append((Path(f.name).stem, df_up))
    else:
        st.info("Esperando archivo(s) meteo...")

# ====================== Procesamiento y visualizaci√≥n ======================
if dfs:
    for nombre, df in dfs:
        ok, msg = validar_columnas_meteo(df)
        if not ok:
            st.warning(f"{nombre}: {msg}")
            continue

        df = df.sort_values("Julian_days").reset_index(drop=True)
        X_real = df[["Julian_days", "TMIN", "TMAX", "Prec"]].to_numpy(float)
        fechas = pd.to_datetime(df["Fecha"])

        pred = modelo.predict(X_real, thr_bajo_medio=THR_BAJO_MEDIO, thr_medio_alto=THR_MEDIO_ALTO)
        pred["Fecha"] = fechas
        pred["Julian_days"] = df["Julian_days"]
        pred["EMERREL acumulado"] = pred["EMERREL(0-1)"].cumsum()
        pred["EMERREL_MA5"] = pred["EMERREL(0-1)"].rolling(window=5, min_periods=1).mean()

        pred["EMEAC (0-1) - m√≠nimo"]    = pred["EMERREL acumulado"] / EMEAC_MIN_DEN
        pred["EMEAC (0-1) - m√°ximo"]    = pred["EMERREL acumulado"] / EMEAC_MAX_DEN
        pred["EMEAC (0-1) - ajustable"] = pred["EMERREL acumulado"] / EMEAC_ADJ_DEN
        for col in ["EMEAC (0-1) - m√≠nimo", "EMEAC (0-1) - m√°ximo", "EMEAC (0-1) - ajustable"]:
            pred[col.replace("(0-1)", "(%)")] = (pred[col] * 100).clip(0, 100)

        # ---- Ventana 1/feb ‚Üí 1/nov para gr√°ficos (con fallback) ----
        years = pred["Fecha"].dt.year.unique()
        yr = int(years[0]) if len(years) == 1 else int(st.sidebar.selectbox("A√±o (reinicio 1/feb ‚Üí 1/nov)", sorted(years), key=f"year_select_{nombre}"))
        fi = pd.Timestamp(year=yr, month=2, day=1)
        ff = pd.Timestamp(year=yr, month=11, day=1)
        m = (pred["Fecha"] >= fi) & (pred["Fecha"] <= ff)
        pred_vis = pred.loc[m].copy()

        rango_personalizado = False
        if pred_vis.empty:
            pred_vis = pred.copy()
            fi, ff = pred_vis["Fecha"].min(), pred_vis["Fecha"].max()
            rango_personalizado = True
            st.info(f"{nombre}: sin datos entre 1/feb y 1/nov; mostrando rango real disponible: {fi.date()} ‚Üí {ff.date()}.")

        pred_vis["EMERREL acumulado (reiniciado)"] = pred_vis["EMERREL(0-1)"].cumsum()
        pred_vis["EMEAC (0-1) - m√≠nimo (rango)"]    = pred_vis["EMERREL acumulado (reiniciado)"] / EMEAC_MIN_DEN
        pred_vis["EMEAC (0-1) - m√°ximo (rango)"]    = pred_vis["EMERREL acumulado (reiniciado)"] / EMEAC_MAX_DEN
        pred_vis["EMEAC (0-1) - ajustable (rango)"] = pred_vis["EMERREL acumulado (reiniciado)"] / EMEAC_ADJ_DEN
        for col in ["EMEAC (0-1) - m√≠nimo (rango)", "EMEAC (0-1) - m√°ximo (rango)", "EMEAC (0-1) - ajustable (rango)"]:
            pred_vis[col.replace("(0-1)", "(%)")] = (pred_vis[col] * 100).clip(0, 100)

        colores_vis = obtener_colores(pred_vis["Nivel_Emergencia_relativa"])

        # ====== FIGURA: EMERREL diario (con MA5 sombreada) ======
        st.subheader("EMERGENCIA RELATIVA DIARIA")
        fig_er = go.Figure()
        fig_er.add_bar(
            x=pred_vis["Fecha"],
            y=pred_vis["EMERREL(0-1)"],
            marker=dict(color=colores_vis.tolist()),
            customdata=pred_vis["Nivel_Emergencia_relativa"].map(
                {"Bajo": "üü¢ Bajo", "Medio": "üü† Medio", "Alto": "üî¥ Alto"}
            ),
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>EMERREL: %{y:.3f}<br>Nivel: %{customdata}<extra></extra>",
            name="EMERREL (0-1)"
        )
        # L√≠nea MA5
        fig_er.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMERREL_MA5"],
            mode="lines", line=dict(width=2),
            name="Media m√≥vil 5 d√≠as",
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>MA5: %{y:.3f}<extra></extra>"
        ))
        # Sombreado tenue bajo MA5
        fig_er.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMERREL_MA5"],
            mode="lines", line=dict(width=0),
            fill="tozeroy", fillcolor="rgba(65,105,225,0.15)",
            hoverinfo="skip", showlegend=False
        ))
        # Niveles de referencia
        low_thr = float(THR_BAJO_MEDIO); med_thr = float(THR_MEDIO_ALTO)
        fig_er.add_trace(go.Scatter(x=[fi, ff], y=[low_thr, low_thr],
            mode="lines", line=dict(color=COLOR_MAP["Bajo"], dash="dot"),
            name=f"Bajo (‚â§ {low_thr:.3f})", hoverinfo="skip"))
        fig_er.add_trace(go.Scatter(x=[fi, ff], y=[med_thr, med_thr],
            mode="lines", line=dict(color=COLOR_MAP["Medio"], dash="dot"),
            name=f"Medio (‚â§ {med_thr:.3f})", hoverinfo="skip"))
        fig_er.add_trace(go.Scatter(x=[None], y=[None], mode="lines",
            line=dict(color=COLOR_MAP["Alto"], dash="dot"),
            name=f"Alto (> {med_thr:.3f})", hoverinfo="skip"))
        fig_er.update_layout(
            xaxis_title="Fecha", yaxis_title="EMERREL (0-1)",
            hovermode="x unified", legend_title="Referencias", height=650
        )
        fig_er.update_xaxes(range=[fi, ff], dtick="D1" if (ff-fi).days <= 31 else "M1",
                            tickformat="%d-%b" if (ff-fi).days <= 31 else "%b")
        fig_er.update_yaxes(rangemode="tozero")
        st.plotly_chart(fig_er, use_container_width=True, theme="streamlit")

        # ====== FIGURA: EMERGENCIA acumulada ======
        st.subheader("EMERGENCIA ACUMULADA DIARIA")
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMEAC (%) - m√°ximo (rango)"],
            mode="lines", line=dict(width=0), name="M√°ximo (reiniciado)",
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>M√°ximo: %{y:.1f}%<extra></extra>"
        ))
        fig.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMEAC (%) - m√≠nimo (rango)"],
            mode="lines", line=dict(width=0), fill="tonexty", name="M√≠nimo (reiniciado)",
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>M√≠nimo: %{y:.1f}%<extra></extra>"
        ))
        fig.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMEAC (%) - ajustable (rango)"],
            mode="lines", line=dict(width=2.5),
            name=f"Umbral ajustable (/{EMEAC_ADJ_DEN:.2f})",
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>Ajustable: %{y:.1f}%<extra></extra>"
        ))
        fig.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMEAC (%) - m√≠nimo (rango)"],
            mode="lines", line=dict(dash="dash", width=1.5),
            name=f"Umbral m√≠nimo (/{EMEAC_MIN_DEN:.2f})",
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>M√≠nimo: %{y:.1f}%<extra></extra>"
        ))
        fig.add_trace(go.Scatter(
            x=pred_vis["Fecha"], y=pred_vis["EMEAC (%) - m√°ximo (rango)"],
            mode="lines", line=dict(dash="dash", width=1.5),
            name=f"Umbral m√°ximo (/{EMEAC_MAX_DEN:.2f})",
            hovertemplate="Fecha: %{x|%d-%b-%Y}<br>M√°ximo: %{y:.1f}%<extra></extra>"
        ))
        for nivel in [25, 50, 75, 90]:
            fig.add_hline(y=nivel, line_dash="dash", opacity=0.6, annotation_text=f"{nivel}%")
        fig.update_layout(
            xaxis_title="Fecha", yaxis_title="EMEAC (%)",
            yaxis=dict(range=[0, 100]), hovermode="x unified",
            legend_title="Referencias", height=600
        )
        fig.update_xaxes(range=[fi, ff], dtick="D1" if (ff-fi).days <= 31 else "M1",
                         tickformat="%d-%b" if (ff-fi).days <= 31 else "%b")
        st.plotly_chart(fig, use_container_width=True, theme="streamlit")

        # ====== TABLA: Resultados en el rango gr√°fico ======
        rango_txt = f"{fi.date()} ‚Üí {ff.date()}" if rango_personalizado else "1/feb ‚Üí 1/nov"
        st.subheader(f"Resultados ({rango_txt}) - {nombre}")
        col_emeac = "EMEAC (%) - ajustable (rango)"
        nivel_icono = {"Bajo": "üü¢ Bajo", "Medio": "üü† Medio", "Alto": "üî¥ Alto"}
        tabla_rango = pred_vis[["Fecha","Julian_days","Nivel_Emergencia_relativa",col_emeac]].copy()
        tabla_rango["Nivel_Emergencia_relativa"] = tabla_rango["Nivel_Emergencia_relativa"].map(nivel_icono)
        tabla_rango = tabla_rango.rename(columns={"Nivel_Emergencia_relativa":"Nivel de EMERREL", col_emeac:"EMEAC (%)"})
        st.dataframe(tabla_rango, use_container_width=True)

        csv_buf = StringIO(); tabla_rango.to_csv(csv_buf, index=False)
        st.download_button(
            f"Descargar resultados (rango) - {nombre}",
            data=csv_buf.getvalue(),
            file_name=f"{nombre}_resultados_rango.csv",
            mime="text/csv"
        )


# ===================== üõ† Depuraci√≥n de serie de entrada =====================
try:
    with st.expander("üõ† Depuraci√≥n de serie de entrada"):
        _df_dbg = merged.copy()
        _df_dbg = _df_dbg.sort_values("Fecha").reset_index(drop=True)
        st.write({
            "primera_fecha": str(_df_dbg["Fecha"].min().date()) if len(_df_dbg)>0 else None,
            "ultima_fecha":  str(_df_dbg["Fecha"].max().date()) if len(_df_dbg)>0 else None,
            "total_filas":   int(len(_df_dbg)),
        })
        st.markdown("**√öltimas 10 fechas efectivas**")
        st.table(_df_dbg[["Fecha"]].tail(10))
except Exception as _e:
    st.warning(f"No se pudo mostrar la depuraci√≥n de la serie de entrada: {_e}")

